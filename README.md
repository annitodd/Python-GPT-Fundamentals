# D-Lab's GPT Fundamentals Workshop

[![DataHub](https://img.shields.io/badge/launch-datahub-blue)](http://dlab.datahub.berkeley.edu/hub/user-redirect/git-pull?repo=https%3A%2F%2Fgithub.com%2Fdlab-berkeley%2FGPT-Fundamentals&urlpath=lab%2Ftree%2FGPT-Fundamentals%2F)
[![Binder](https://mybinder.org/badge_logo.svg)](https://mybinder.org/v2/gh/dlab-berkeley/GPT-Fundamentals/HEAD)
[![License: CC BY 4.0](https://img.shields.io/badge/License-CC_BY_4.0-lightgrey.svg)](https://creativecommons.org/licenses/by/4.0/)

This repository contains the materials for D-Lab's GPT Fundamentals workshop. We recommend attending [Python Fundamentals](https://github.com/dlab-berkeley/Python-Fundamentals),
[Python Intermediate](https://github.com/dlab-berkeley/Python-Intermediate), and [Python Data Wrangling](https://github.com/dlab-berkeley/Python-Data-Wrangling) prior to this workshop.

Check out D-Lab's [Learning Pathways](https://dlab-berkeley.github.io/dlab-workshops/python_path.html) to figure out which of our workshops to take!

## Workshop Goals

This workshop offers a general introduction to the GPT (Generative Pretrained Transformers) model. We will explore how they reflect and shape our cultural narratives and social interactions, and which drawbacks and constraints they have. We will explore the transformer architecture upon which GPTs are built, how GPTs encode natural language into embeddings, and how it predicts text. We will also use geometric similarity approaches to represent varying types of similarity between words. 

## Learning Objectives

After this workshop, you will be able to:

- Understand what GPTs are and how they function.
- Why the transformer architecture is an imporant development in Natural Language Processing and AI.
- How GPTs encode natural language into embeddings.
- How GPTs encode language into embeddings.

This workshop does **not** cover the following:

- Prompt Engineering. We will cover this in a future workshop.
- The fundamentals of Python. See the list of workshops below to get a better grasp on the Python language used in this workshop.


## Installation Instructions

We will use Python to go through the workshop materials. Complete the following steps:

1. Install the [Anaconda](https://www.anaconda.com/download) distribution of Python on your machine.
2. Download these workshop materials:
    * Click the green "Code" button in the top right of the repository information.
    * Click "Download Zip".
    * Extract this file to a folder on your computer where you can easily access it (we recommend Desktop).
3. Optional: if youâ€™re familiar with git, you can instead clone this repository by opening a terminal and entering `git clone https://github.com/dlab-berkeley/GPT-Fundamentals.git`

### Minimum Specifications:
* Processor: At least a modern quad-core processor (i5 or i7). More cores are beneficial for parallel processing.
* RAM: 8 GB is the bare minimum, but 16 GB or more is recommended, especially for larger models.
* Storage: SSD (Solid State Drive) is preferred for faster data reading and writing.
* Operating System: Linux or Windows with Python environment set up.

### Ideal Specifications:
* Processor: High-end i7 or i9, or an equivalent AMD Ryzen processor.
* RAM: 16 GB or more.
* GPU: A dedicated GPU with CUDA support is highly beneficial. Models like NVIDIA RTX 2060 or better can significantly speed up computation. The larger the model, the more VRAM is needed. * For the largest GPT-2 model, a GPU with at least 8 GB of VRAM is recommended.
* Storage: SSD with sufficient space for the model and your datasets.


## Is Python not Working on Your Computer?

If you do not have Python installed and the materials loaded on your
workshop by the time it starts, we *strongly* recommend using the UC Berkeley
Datahub to run the materials for these lessons. You can access the DataHub by
clicking the following button:

[![DataHub](https://img.shields.io/badge/launch-datahub-blue)](http://dlab.datahub.berkeley.edu/hub/user-redirect/git-pull?repo=https%3A%2F%2Fgithub.com%2Fdlab-berkeley%2FGPT-Fundamentals&urlpath=lab%2Ftree%2FGPT-Fundamentals%2F)

The DataHub downloads this repository, along with any necessary packages, and
allows you to run the materials in an RStudio instance on UC Berkeley's servers.
No installation is necessary from your end - you only need an internet browser
and a CalNet ID to log in. By using the DataHub, you can save your work and come
back to it at any time. When you want to return to your saved work, just go
straight to the [D-Lab DataHub](https://dlab.datahub.berkeley.edu), sign in, and
you click on the `GPT-Fundamentals` folder.

If you don't have a Berkeley CalNet ID, you can still run these lessons in the cloud, by clicking this button:

[![Binder](https://mybinder.org/badge_logo.svg)](https://mybinder.org/v2/gh/dlab-berkeley/GPT-Fundamentals/HEAD)

By using this button, however, you cannot save your work.

# Other D-Lab Python Workshops

Here are other Python workshops offered by the D-Lab:

## Introductory Workshops

* [Python Fundamentals](https://github.com/dlab-berkeley/Python-Fundamentals)
* [Python Intermediate](https://github.com/dlab-berkeley/Python-Intermediate) 
* [Python Data Wrangling](https://github.com/dlab-berkeley/Python-Data-Wrangling)
* [Python Data Visualization](https://github.com/dlab-berkeley/Python-Data-Visualization)
* [Python Geospatial Fundamentals](https://github.com/dlab-berkeley/Geospatial-Data-and-Mapping-in-Python)

## Advanced Workshops

* [Python Web Scraping and APIs](https://github.com/dlab-berkeley/Python-Web-Scraping)
* [Python Machine Learning](https://github.com/dlab-berkeley/Python-Machine-Learning)
* [Python Text Analysis](https://github.com/dlab-berkeley/Python-Text-Analysis)
* [Python Deep Learning](https://github.com/dlab-berkeley/Python-Deep-Learning)


# About the UC Berkeley D-Lab

D-Lab works with Berkeley faculty, research staff, and students to advance data-intensive social science and humanities research. Our goal at D-Lab is to provide practical training, staff support, resources, and space to enable you to use R for your own research applications. Our services cater to all skill levels and no programming, statistical, or computer science backgrounds are necessary. We offer these services in the form of workshops, one-to-one consulting, and working groups that cover a variety of research topics, digital tools, and programming languages.  

Visit the [D-Lab homepage](https://dlab.berkeley.edu/) to learn more about us. You can view our [calendar](https://dlab.berkeley.edu/events/calendar) for upcoming events, learn about how to utilize our [consulting](https://dlab.berkeley.edu/consulting) and [data](https://dlab.berkeley.edu/data) services, and check out upcoming [workshops](https://dlab.berkeley.edu/events/workshops).

# Contributors

Tom van Nuenen

Renata Barreto
